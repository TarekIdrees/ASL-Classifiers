{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_classifier_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Set up colab for ASL data from kaggel**"
      ],
      "metadata": {
        "id": "3zqo5Ua0bsLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT5u73kyUfFJ"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "IUUmmXFgVJt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "gP7REvPpVQxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "vnlJ5LCkVX1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download grassknoted/asl-alphabet"
      ],
      "metadata": {
        "id": "f68eq3AgVsbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip asl-alphabet.zip"
      ],
      "metadata": {
        "id": "bfFFY6IMWMzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import needed libraries**"
      ],
      "metadata": {
        "id": "MUeGgdP4b2RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import keras\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "XH9xGgwKXPq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'asl_alphabet_train//asl_alphabet_train'\n",
        "test_dir = 'asl_alphabet_test//asl_alphabet_test'\n",
        "labels_dict = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11,\n",
        "               'M': 12,\n",
        "               'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23,\n",
        "               'Y': 24,\n",
        "               'Z': 25, 'space': 26, 'del': 27, 'nothing': 28}"
      ],
      "metadata": {
        "id": "rrOjUDJqbGh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imageProcessing(temp_imges,labels):\n",
        "    images = []\n",
        "    flat_data = []\n",
        "    for temp_img in temp_imges:\n",
        "              # Blur the image to improve performance\n",
        "              temp = cv2.GaussianBlur(temp_img, (3, 3), 0)\n",
        "              # Use canny edge detection\n",
        "              temp = cv2.Canny(temp, threshold1=4, threshold2=100)\n",
        "              # flatten the data to be prepared\n",
        "              flat_data.append(temp.flatten())\n",
        "                 \n",
        "    #convert X_train to numpy\n",
        "    X_train = np.array(flat_data)\n",
        "    #convert Y_train to numpy\n",
        "    labels = np.array(labels)\n",
        "    #Normalize pixels\n",
        "    X_train = X_train.astype('float32')/255.0\n",
        "    Y_train = labels\n",
        "    print()\n",
        "    print('Loaded', len(X_train), 'images for training,', 'Train data shape =', X_train.shape)\n",
        "    return X_train,Y_train"
      ],
      "metadata": {
        "id": "nsgH56t-KJ1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data_RGB():\n",
        "    size = 90, 90\n",
        "    images=[]\n",
        "    labels = []\n",
        "    images_per_folder=0\n",
        "    print(\"LOADING DATA FROM : \", end=\"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end=' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "          if images_per_folder == 1000:\n",
        "            images_per_folder=0\n",
        "            break;\n",
        "          # read image\n",
        "          temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
        "          # resize image\n",
        "          temp_img = cv2.resize(temp_img, size)\n",
        "          images.append(temp_img.flatten())\n",
        "          labels.append(labels_dict[folder]) \n",
        "          images_per_folder+=1 \n",
        "    #convert X_train to numpy \n",
        "    Y_train = np.array(labels)\n",
        "    #convert Y_train to numpy\n",
        "    X_train = np.array(images)\n",
        "    print()\n",
        "    print('Loaded', len(X_train), 'images for training,', 'Train data shape =', X_train.shape)\n",
        "    return X_train,Y_train"
      ],
      "metadata": {
        "id": "PnR3WaiwWmRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data_BINARY():\n",
        "    size = 90, 90\n",
        "    images=[]\n",
        "    labels = []\n",
        "    images_per_folder=0\n",
        "    print(\"LOADING DATA FROM : \", end=\"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end=' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "          if images_per_folder == 1000:\n",
        "            images_per_folder=0\n",
        "            break;\n",
        "          # read image\n",
        "          temp_img = cv2.imread(train_dir + '/' + folder + '/' + image,0)\n",
        "          # resize image\n",
        "          temp_img = cv2.resize(temp_img, size)\n",
        "          # Binary classification\n",
        "          _,threshold = cv2.threshold(temp_img, 149, 255, cv2.THRESH_BINARY)\n",
        "          images.append(threshold)\n",
        "          labels.append(labels_dict[folder]) \n",
        "          images_per_folder+=1\n",
        "\n",
        "    return images,labels"
      ],
      "metadata": {
        "id": "ClUKKnBZSdd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_data_GRAY():\n",
        "    size = 90, 90\n",
        "    images=[]\n",
        "    labels = []\n",
        "    images_per_folder=0\n",
        "    print(\"LOADING DATA FROM : \", end=\"\")\n",
        "    for folder in os.listdir(train_dir):\n",
        "        print(folder, end=' | ')\n",
        "        for image in os.listdir(train_dir + \"/\" + folder):\n",
        "          if images_per_folder == 1000:\n",
        "            images_per_folder=0\n",
        "            break;\n",
        "          # read image\n",
        "          temp_img = cv2.imread(train_dir + '/' + folder + '/' + image,0)\n",
        "          # resize image\n",
        "          temp_img = cv2.resize(temp_img, size)\n",
        "          images.append(temp_img.flatten())\n",
        "          labels.append(labels_dict[folder]) \n",
        "          images_per_folder+=1 \n",
        "    #convert Y_train to numpy \n",
        "    Y_train = np.array(labels)\n",
        "    #convert X_train to numpy\n",
        "    X_train = np.array(images)\n",
        "    #Normalize pixels of X_train\n",
        "    X_train = X_train.astype('float32')/255.0\n",
        "    print()\n",
        "    print('Loaded', len(X_train), 'images for training,', 'Train data shape =', X_train.shape)\n",
        "    return X_train,Y_train"
      ],
      "metadata": {
        "id": "5EJB8qG7R4Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data_RGB():\n",
        "    labels = []\n",
        "    flat_data = []\n",
        "    size = 90, 90\n",
        "    for image in os.listdir(test_dir):\n",
        "        # read image\n",
        "        temp_img = cv2.imread(test_dir + '/'+ image)\n",
        "        # resize image\n",
        "        temp_img = cv2.resize(temp_img, size)\n",
        "        # flatten the data to be prepared\n",
        "        flat_data.append(temp_img.flatten())\n",
        "        labels.append(labels_dict[image.split('_')[0]])\n",
        "\n",
        "    #convert X_test to numpy\n",
        "    X_test = np.array(flat_data)\n",
        "    #convert Y_test to numpy\n",
        "    Y_test = np.array(labels)\n",
        "    print(\"\\n\")\n",
        "    print('Loaded', len(X_test), 'images for testing,', 'Test data shape =', X_test.shape)\n",
        "\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "Wesb58lacCT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data_GRAY():\n",
        "    labels = []\n",
        "    flat_data = []\n",
        "    size = 90, 90\n",
        "    for image in os.listdir(test_dir):\n",
        "        # read image\n",
        "        temp_img = cv2.imread(test_dir + '/'+ image,0)\n",
        "        # resize image\n",
        "        temp_img = cv2.resize(temp_img, size)\n",
        "        # flatten the data to be prepared\n",
        "        flat_data.append(temp_img.flatten())\n",
        "        labels.append(labels_dict[image.split('_')[0]])\n",
        "\n",
        "    #convert X_test to numpy\n",
        "    X_test = np.array(flat_data)\n",
        "    #normalize X_test\n",
        "    X_test = X_test.astype('float32')/255.0\n",
        "    #convert Y_test to numpy\n",
        "    Y_test = np.array(labels)\n",
        "    print(\"\\n\")\n",
        "    print('Loaded', len(X_test), 'images for testing,', 'Test data shape =', X_test.shape)\n",
        "\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "dQtvRrwoTI5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data_BINARY():\n",
        "    labels = []\n",
        "    flat_data = []\n",
        "    size = 90, 90\n",
        "    for image in os.listdir(test_dir):\n",
        "        # read image\n",
        "        temp_img = cv2.imread(test_dir + '/'+ image,0)\n",
        "        # resize image\n",
        "        temp_img = cv2.resize(temp_img, size)\n",
        "        # Binary classification\n",
        "        _,threshold = cv2.threshold(temp_img, 149, 255, cv2.THRESH_BINARY)\n",
        "        # flatten the data to be prepared\n",
        "        flat_data.append(threshold.flatten())\n",
        "        labels.append(labels_dict[image.split('_')[0]])\n",
        "    #convert X_Test to numpy\n",
        "    X_test = np.array(flat_data)\n",
        "    #convert Y_test to numpy\n",
        "    Y_test = np.array(labels)\n",
        "    #normalize pixels of X_test \n",
        "    X_test = X_test.astype('float32')/255.0\n",
        "    print(\"\\n\")\n",
        "    print('Loaded', len(X_test), 'images for testing,', 'Test data shape =', X_test.shape)\n",
        "\n",
        "    return X_test, Y_test"
      ],
      "metadata": {
        "id": "h_SXmIfPTar6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data with RGB**"
      ],
      "metadata": {
        "id": "6vkRAXzKhpp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_RGB, Y_train_RGB =  load_train_data_RGB()\n",
        "X_test_RGB, Y_test_RGB = load_test_data_RGB()"
      ],
      "metadata": {
        "id": "cK-DK9fUXG8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d6c29d-091e-4d7d-c3db-a6e7dcd4dfed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING DATA FROM : nothing | del | space | X | T | M | C | K | V | U | J | P | A | Z | E | G | I | R | Q | N | S | B | O | D | H | Y | W | F | L | \n",
            "Loaded 29000 images for training, Train data shape = (29000, 24300)\n",
            "\n",
            "\n",
            "Loaded 28 images for testing, Test data shape = (28, 24300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data with Gray**"
      ],
      "metadata": {
        "id": "dOtcEeXlhx6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_GRAY, Y_train_GRAY =  load_train_data_GRAY()\n",
        "X_test_GRAY, Y_test_GRAY = load_test_data_GRAY()"
      ],
      "metadata": {
        "id": "-2Z9qJ_bSq3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c3687c1-1388-4b4a-8bd1-76582edd9bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING DATA FROM : S | H | U | C | W | E | Q | X | M | F | J | del | N | D | R | I | O | nothing | Z | G | V | space | P | T | Y | L | K | B | A | \n",
            "Loaded 29000 images for training, Train data shape = (29000, 8100)\n",
            "\n",
            "\n",
            "Loaded 28 images for testing, Test data shape = (28, 8100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data with Binary**"
      ],
      "metadata": {
        "id": "HFbdoGdth2YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_BINARY, Y_train_BINARY =  load_train_data_BINARY()\n",
        "X_train_BINARY, Y_train_BINARY = imageProcessing(X_train_BINARY, Y_train_BINARY)\n",
        "X_test_BINARY, Y_test_BINARY = load_test_data_BINARY()"
      ],
      "metadata": {
        "id": "Ma48BohJSuiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e764afab-1e4d-4798-bb63-9b26c55078bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING DATA FROM : B | W | L | space | H | K | S | nothing | M | A | P | R | Q | E | Z | U | V | O | J | X | C | T | Y | D | N | del | I | G | F | \n",
            "Loaded 29000 images for training, Train data shape = (29000, 8100)\n",
            "\n",
            "\n",
            "Loaded 28 images for testing, Test data shape = (28, 8100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions of Classifiers**"
      ],
      "metadata": {
        "id": "h4V5X_cLh7UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SVM(X_train,Y_train):\n",
        "    model = SVC(kernel='linear')\n",
        "    model.fit(X_train, Y_train)\n",
        "    return model\n",
        "\n",
        "def Naive_Base(X_train,Y_train):\n",
        "    gnb = GaussianNB()\n",
        "    model = gnb.fit(X_train, Y_train)\n",
        "    return model\n",
        "\n",
        "def KNN(X_train,Y_train):\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "    model.fit(X_train, Y_train)\n",
        "    return model\n",
        "\n",
        "def DecisionTree(X_train,Y_train):\n",
        "    clf = DecisionTreeClassifier()\n",
        "    clf = clf.fit(X_train, Y_train)\n",
        "    return clf\n",
        "    \n",
        "def MLP(X_train,Y_train):\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
        "    mlp.fit(X_train, Y_train)\n",
        "    return mlp\n",
        "\n",
        "def logisticRegression(X_train,Y_train):\n",
        "  lR = LogisticRegression()\n",
        "  lR.fit(X_train,Y_train)\n",
        "  return lR\n"
      ],
      "metadata": {
        "id": "LKHt6zDScHm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train RGB X_train using Decision Tree**"
      ],
      "metadata": {
        "id": "hNzNnzpPiEn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#call model on training data \n",
        "model = DecisionTree(X_train_RGB, Y_train_RGB)\n",
        "Y_pred_RGB = model.predict(X_test_RGB)"
      ],
      "metadata": {
        "id": "peSCzsJWdO4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate Accuracy, Precision and Recall**"
      ],
      "metadata": {
        "id": "ZLYwbmeBiMfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "accuracy = accuracy_score(Y_test_RGB, Y_pred_RGB)\n",
        "print('Model accuracy is: ', accuracy)\n",
        "\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\", precision_score(Y_test_RGB, Y_pred_RGB, average='micro'))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\", recall_score(Y_test_RGB, Y_pred_RGB, average='micro'))"
      ],
      "metadata": {
        "id": "6PPSN2m5Lp5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04357dff-e622-4d30-a36f-c03cf79a07f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is:  0.9642857142857143\n",
            "Precision: 0.9642857142857143\n",
            "Recall: 0.9642857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Gray X_train using KNN**"
      ],
      "metadata": {
        "id": "nuUhcPRwigkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KNN(X_train_GRAY, Y_train_GRAY)\n",
        "Y_pred_GRAY = model.predict(X_test_GRAY)"
      ],
      "metadata": {
        "id": "B3NrcKEfiBih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate Accuracy, Precision and Recall**"
      ],
      "metadata": {
        "id": "w8M6ZArAirdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "accuracy = accuracy_score(Y_test_GRAY, Y_pred_GRAY)\n",
        "print('Model accuracy is: ', accuracy)\n",
        "\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\", precision_score(Y_test_GRAY, Y_pred_GRAY, average='micro'))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\", recall_score(Y_test_GRAY, Y_pred_GRAY, average='micro'))"
      ],
      "metadata": {
        "id": "Sblg_VpoLw9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb027f7c-0138-483a-c084-d28795f8b199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is:  0.8928571428571429\n",
            "Precision: 0.8928571428571429\n",
            "Recall: 0.8928571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Binary X_train using MLP**"
      ],
      "metadata": {
        "id": "acQj0HqwitC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(X_train_BINARY,Y_train_BINARY)\n",
        "Y_pred_BINARY = model.predict(X_test_BINARY)"
      ],
      "metadata": {
        "id": "mfrvqra_nJtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate Accuracy, Precision and Recall**"
      ],
      "metadata": {
        "id": "YfXbW4E1ixqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "accuracy = accuracy_score(Y_test_BINARY, Y_pred_BINARY)\n",
        "print('Model accuracy is: ', accuracy)\n",
        "\n",
        "# Model Precision: what percentage of positive tuples are labeled as such?\n",
        "print(\"Precision:\", precision_score(Y_test_BINARY, Y_pred_BINARY, average='micro'))\n",
        "\n",
        "# Model Recall: what percentage of positive tuples are labelled as such?\n",
        "print(\"Recall:\", recall_score(Y_test_BINARY, Y_pred_BINARY, average='micro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_dB_4dJnWMn",
        "outputId": "811f0738-01d7-43d3-8407-61eec6e8056e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is:  0.10714285714285714\n",
            "Precision: 0.10714285714285714\n",
            "Recall: 0.10714285714285714\n"
          ]
        }
      ]
    }
  ]
}